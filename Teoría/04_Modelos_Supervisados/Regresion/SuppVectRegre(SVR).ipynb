{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMElXbHs30JXZACKG+CWUb7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kevin2558/Data_Science_Borrador/blob/main/04_Modelos_Supervisados/Regresion/SuppVectRegre(SVR).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Regressor (SVR)\n",
        "\n",
        "Extensión del modelo Support Vector Machines (SVM) para tareas de regresión. A diferencia de los métodos tradicionales que minimizan directamente el error, SVR buscar encontrar una función que se desvíe lo menos posible de los datos dentro de un margen de tolerancia, penalizando únicamente los errores que exceden ese margen.\n",
        "\n",
        "Este enfoque permite construir modelos robustos frente a valores atípicos y con buen poder de generalización. SVR puede adaptarse a relaciones lineales y no lineales mediante el uso de funciones *kernel*, lo que lo convierte en una herrameinto flexible para problemas complejos de regresión."
      ],
      "metadata": {
        "id": "9ae2gqCUAqhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carguemos las librerías necesarias para la realización del modelo."
      ],
      "metadata": {
        "id": "bgXYPAwABXkA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAfRIawwNnWA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carguemos el dataset a utilizar."
      ],
      "metadata": {
        "id": "8RE7iyGWBgDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"harlfoxem/housesalesprediction\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdNDaTDEOdc8",
        "outputId": "9a954cb5-74d7-429d-f866-12bab3e0ffb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/housesalesprediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path + \"/kc_house_data.csv\")"
      ],
      "metadata": {
        "id": "SI_JVXxhOh-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separemos las variables entre numéricas y categóricas."
      ],
      "metadata": {
        "id": "D47gyABgBkQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num = [\"sqft_living\", \"bathrooms\", \"lat\", \"long\", \"sqft_lot\", \"bedrooms\", \"yr_built\"]\n",
        "cat = [\"zipcode\", \"waterfront\", \"condition\", \"grade\"]"
      ],
      "metadata": {
        "id": "5MPGtMKeOkl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[num + cat]\n",
        "y = df[\"price\"]"
      ],
      "metadata": {
        "id": "wuoROvnAOmuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separemos los datos entre entrenamiento y validación."
      ],
      "metadata": {
        "id": "ikhQ1x-FBsck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr,X_te,y_tr,y_te = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "F0jalG33OoBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocesamiento."
      ],
      "metadata": {
        "id": "ccAoAb5HBvYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prep = ColumnTransformer([\n",
        "    (\"num\", RobustScaler(), num),\n",
        "    (\"cat\", OneHotEncoder(), cat)\n",
        "])"
      ],
      "metadata": {
        "id": "DAkKy64DOrJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carguemos la librería del modelo."
      ],
      "metadata": {
        "id": "4saV4M0EBw2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR"
      ],
      "metadata": {
        "id": "eDNnuLMaO3PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construyamos el pipeline del modelo SVR."
      ],
      "metadata": {
        "id": "TRCSTVx1BzMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svr = Pipeline([\n",
        "    (\"prep\", prep),\n",
        "    (\"model\", SVR(\n",
        "        kernel=\"poly\",\n",
        "        C=10, # Parametro de regularizacion\n",
        "        epsilon=0.01, # Tolerancia,\n",
        "        gamma=\"scale\" # Parametro de kernel\n",
        "    ))\n",
        "])"
      ],
      "metadata": {
        "id": "7tTd_fKRO6lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métricas para la evaluación de los modelos."
      ],
      "metadata": {
        "id": "LNBlJF1eB2H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mse(y_true, y_pred))"
      ],
      "metadata": {
        "id": "_k8cpxgGQoZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realicemos el entrenamiento del modelo, la predicción y la evaluación del mismo, a través de las métricas ya definidas."
      ],
      "metadata": {
        "id": "g6OsZio8B60T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svr.fit(X_tr,y_tr)\n",
        "pred_svr = svr.predict(X_te)\n",
        "print(\"RMSE:\", rmse(y_te, pred_svr))\n",
        "print(\"r2_score:\", r2_score(y_te, pred_svr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcwwVl3LPma0",
        "outputId": "45c538f8-dc2f-481e-d174-265902b0e938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 403822.0885114913\n",
            "r2_score: -0.07868650359795493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notemos que en este caso no funcionó."
      ],
      "metadata": {
        "id": "t2PrOlz-CNwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probemos con otros hiperparámetros."
      ],
      "metadata": {
        "id": "Z9V8xCf_CSkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svr = Pipeline([\n",
        "    (\"prep\", prep),\n",
        "    (\"model\", SVR(\n",
        "        kernel=\"rbf\",\n",
        "        C=100, # Parametro de regularizacion\n",
        "        epsilon=0.01, # Tolerancia,\n",
        "        gamma=\"scale\" # Parametro de kernel\n",
        "    ))\n",
        "])\n",
        "\n",
        "svr.fit(X_tr,y_tr)\n",
        "pred_svr = svr.predict(X_te)\n",
        "print(\"RMSE:\", rmse(y_te, pred_svr))\n",
        "print(\"r2_score:\", r2_score(y_te, pred_svr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLfynK9JQMQl",
        "outputId": "25c8d0eb-8b14-451b-c750-a3c80cb9b801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 382808.7319658623\n",
            "r2_score: 0.03065410616730102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notemos que la predicción en este caso es realmente mala, esto se puede deber a la no separabilidad de las variables objetivos."
      ],
      "metadata": {
        "id": "SkmMbmfCCVsd"
      }
    }
  ]
}