{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPintQPNJWjVNGfEY8KL7GR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kevin2558/Data_Science/blob/main/02_Preprocesamiento/Desbalanceo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Datos desbalanceados**\n",
        "\n",
        "En tareas de clasificación, si una clase aparece mucho más que otra (por ejemplo, 95% clase 0 y 5% clase 1), muchos modelos simplemente predicen la clase mayoritaria.\n",
        "\n",
        "Esto genera falsos positivos o falsos negativos críticos, especialmente en:\n",
        "\n",
        "- Detección de fraude\n",
        "- Diagnóstico médico\n",
        "- Riesgo financiero\n",
        "\n",
        "La solución a esto es usar técnicas como SMOTE, SMOTETomek, ADASYN, RandomUnderSampler, etc. antes del entrenamiento del modelo."
      ],
      "metadata": {
        "id": "dU5ylYp4aPmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos un ejemplo comparativo para utilizar los samplers.\n",
        "\n",
        "**Sin balancear (baseline)**\n",
        "- Entrenamos el modelo tal cual, sin hacer ningún ajuste.\n",
        "- Puede tener alta accuracy, pero pésimo recall para la clase minoritaria.\n",
        "\n",
        "**SMOTE**\n",
        "- Genera ejemplos sintéticos de la clase minoritaria interpolando entre vecinos.\n",
        "- Ayuda cuando hay pocos datos minoritarios y no queremos perder datos de la clase mayoritaria.\n",
        "\n",
        "**RandomUnderSampler**\n",
        "- Elimina aleatoriamente muestras de la clase mayoritaria.\n",
        "- Es útil cuando se prefiere un dataset más pequeño y balanceado, pero puede perder información.\n",
        "\n",
        "**SMOTETomek**\n",
        "- Combina SMOTE con Tomek Links, que remueve puntos ambiguos entre clases (cerca de la frontera).\n",
        "- Mejora la separación de clases y reduce ruido.\n",
        "\n",
        "**ADASYN (Adaptive Synthetic Sampling)**\n",
        "- Variante de SMOTE que genera más ejemplos sintéticos donde la clase minoritaria es más difícil de aprender (zonas de frontera).\n",
        "- Focaliza el oversampling.\n",
        "\n"
      ],
      "metadata": {
        "id": "XsT-f7NpatLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "# Samplers\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "# Dataset simulado desbalanceado\n",
        "X, y = make_classification(\n",
        "    n_samples=1000, n_features=10,\n",
        "    weights=[0.9, 0.1], random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
        "\n",
        "# Lista de técnicas a evaluar\n",
        "samplers = {\n",
        "    \"Baseline (Sin balancear)\": None,\n",
        "    \"SMOTE\": SMOTE(random_state=42),\n",
        "    \"RandomUnderSampler\": RandomUnderSampler(random_state=42),\n",
        "    \"SMOTETomek\": SMOTETomek(random_state=42),\n",
        "    \"ADASYN\": ADASYN(random_state=42)\n",
        "}\n",
        "\n",
        "for nombre, sampler in samplers.items():\n",
        "    print(f\"\\n{'='*30}\\n{nombre}\\n{'='*30}\")\n",
        "\n",
        "    if sampler is None:\n",
        "        # Sin balanceo\n",
        "        pipeline = ImbPipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('model', LogisticRegression())\n",
        "        ])\n",
        "    else:\n",
        "        # Con técnica de balanceo\n",
        "        pipeline = ImbPipeline([\n",
        "            ('sampler', sampler),\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('model', LogisticRegression())\n",
        "        ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    print(classification_report(y_test, y_pred, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBDld-GsazfO",
        "outputId": "f589c72c-2826-4ec2-b38b-f05df0a42221"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "Baseline (Sin balancear)\n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.940     0.978     0.958       224\n",
            "           1      0.706     0.462     0.558        26\n",
            "\n",
            "    accuracy                          0.924       250\n",
            "   macro avg      0.823     0.720     0.758       250\n",
            "weighted avg      0.916     0.924     0.917       250\n",
            "\n",
            "\n",
            "==============================\n",
            "SMOTE\n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.976     0.897     0.935       224\n",
            "           1      0.477     0.808     0.600        26\n",
            "\n",
            "    accuracy                          0.888       250\n",
            "   macro avg      0.727     0.853     0.767       250\n",
            "weighted avg      0.924     0.888     0.900       250\n",
            "\n",
            "\n",
            "==============================\n",
            "RandomUnderSampler\n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.980     0.875     0.925       224\n",
            "           1      0.440     0.846     0.579        26\n",
            "\n",
            "    accuracy                          0.872       250\n",
            "   macro avg      0.710     0.861     0.752       250\n",
            "weighted avg      0.924     0.872     0.889       250\n",
            "\n",
            "\n",
            "==============================\n",
            "SMOTETomek\n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.976     0.893     0.932       224\n",
            "           1      0.467     0.808     0.592        26\n",
            "\n",
            "    accuracy                          0.884       250\n",
            "   macro avg      0.721     0.850     0.762       250\n",
            "weighted avg      0.923     0.884     0.897       250\n",
            "\n",
            "\n",
            "==============================\n",
            "ADASYN\n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.985     0.853     0.914       224\n",
            "           1      0.411     0.885     0.561        26\n",
            "\n",
            "    accuracy                          0.856       250\n",
            "   macro avg      0.698     0.869     0.737       250\n",
            "weighted avg      0.925     0.856     0.877       250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ab73bb"
      },
      "source": [
        "## Conclusiones de los resultados\n",
        "\n",
        "Observando las métricas de `precision`, `recall` y `f1-score` para la clase minoritaria (clase 1) en cada técnica de balanceo, podemos sacar las siguientes conclusiones:\n",
        "\n",
        "*   **Baseline (Sin balancear):** La precisión es alta (0.706), lo que significa que cuando predice la clase 1, es bastante acertado. Sin embargo, el recall es bajo (0.462), indicando que solo identifica correctamente un pequeño porcentaje de los casos reales de la clase 1. El f1-score (0.558) es moderado. Esto es típico en datasets desbalanceados, donde el modelo tiende a predecir la clase mayoritaria.\n",
        "\n",
        "*   **SMOTE:** SMOTE mejora significativamente el recall para la clase 1 (0.808) en comparación con la baseline, lo que significa que identifica una mayor proporción de los casos reales de la clase 1. Sin embargo, la precisión para la clase 1 disminuye (0.477), lo que indica que cuando predice la clase 1, hay más falsos positivos. El f1-score (0.600) es mejor que la baseline.\n",
        "\n",
        "*   **RandomUnderSampler:** Similar a SMOTE, RandomUnderSampler también mejora el recall para la clase 1 (0.846) de manera considerable. La precisión para la clase 1 (0.440) es la más baja entre las técnicas de balanceo, resultando en más falsos positivos. El f1-score (0.579) es comparable al de SMOTE.\n",
        "\n",
        "*   **SMOTETomek:** Esta técnica combinada muestra un recall para la clase 1 (0.808) similar a SMOTE. La precisión para la clase 1 (0.467) es ligeramente menor que SMOTE. El f1-score (0.592) es muy similar al de SMOTE.\n",
        "\n",
        "*   **ADASYN:** ADASYN logra el recall más alto para la clase 1 (0.885), identificando la mayor proporción de casos reales de la clase 1. No obstante, tiene la precisión más baja para la clase 1 (0.411), lo que resulta en el mayor número de falsos positivos. El f1-score (0.561) es similar a la baseline.\n",
        "\n",
        "**En resumen:**\n",
        "\n",
        "Las técnicas de balanceo (SMOTE, RandomUnderSampler, SMOTETomek, ADASYN) logran mejorar significativamente el **recall** para la clase minoritaria (clase 1) en comparación con el modelo sin balancear. Esto es crucial en escenarios donde es importante identificar la mayoría de los casos positivos (por ejemplo, detectar enfermedades o fraude).\n",
        "\n",
        "Sin embargo, esta mejora en el recall generalmente viene con una disminución en la **precisión** para la clase 1, lo que significa que hay un aumento en los falsos positivos.\n",
        "\n",
        "La elección de la mejor técnica dependerá del problema específico y de la métrica que se priorice. Si minimizar los falsos negativos es más importante, técnicas como ADASYN o RandomUnderSampler podrían ser preferibles (aunque a costa de más falsos positivos). Si se busca un equilibrio entre precisión y recall, SMOTE o SMOTETomek podrían ser buenas opciones."
      ]
    }
  ]
}