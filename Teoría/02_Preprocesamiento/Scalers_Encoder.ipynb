{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAt2tfumtHm6ETIghweaMX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kevin2558/Data_Science_Borrador/blob/main/02_Preprocesamiento/Scalers_Encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Escalamiento y Codificación de Variables\n",
        "\n",
        "En los modelos de ML, la calidad de los datos de entrada es tan importante como el modelo en sí mismo. Por esto, se hace necesario el preprocesamiento de los datos mediante técnicas como el escalamiento de variables numéricas y la codificación de variables categóricas.\n",
        "\n",
        "Veamos como se realiza este proceso"
      ],
      "metadata": {
        "id": "HwAb0wo8vpG3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HaDR6EbovUJ5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procedamos a crear un dataset de ejemplo para ver los preprocesamientos en acción. Construiremos dos variables numéricas (edad, ingreso) y una variables categóricas (ciudad)."
      ],
      "metadata": {
        "id": "Xxbd5ayGwSTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({\n",
        "    'edad': [25, 32, 47, 51, 62],\n",
        "    'ingreso': [50000, 60000, 80000, 120000, 150000],\n",
        "    'ciudad': ['Santiago', 'Valparaíso', 'Santiago', 'Temuco', 'Temuco']\n",
        "})\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91bEuXGtwbNm",
        "outputId": "a22b10b0-f845-4b0a-d505-5e55f3a72a54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   edad  ingreso      ciudad\n",
            "0    25    50000    Santiago\n",
            "1    32    60000  Valparaíso\n",
            "2    47    80000    Santiago\n",
            "3    51   120000      Temuco\n",
            "4    62   150000      Temuco\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procedamos a separar las variables por tipo."
      ],
      "metadata": {
        "id": "RD8IyvqDwqSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = ['edad', 'ingreso']\n",
        "categorical_features = ['ciudad']"
      ],
      "metadata": {
        "id": "VAsQvtlywpq5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Escaladores y codificador\n",
        "\n",
        "- StandardScaler\n",
        "  \n",
        "  Centra los datos (media = 0) y escala para que la desviación estándar sea 1. Se usa cuando los datos están distribuidos normalmente (sin muchos outliers).\n",
        "\n",
        "- RobustScaler\n",
        "\n",
        "  Escala según la mediana y el rango intercuartil (IQR), lo que lo hace resistente a la presencia de outliers. Útil cuando hay valores extremos que puedes distorsionar el modelo.\n",
        "\n",
        "- OneHotEncoder\n",
        "\n",
        "  Convierte las variables categóricas a columnas dummy (0/1). Importante cuando los modelos no pueden manejar texto directamente.\n",
        "\n",
        "# ColumnTransformer\n",
        "\n",
        "  Con esto podemos combinar los transformadores para aplicar escalado a las variables numéricas y one hot encoding a las variables numéricas.\n",
        "\n",
        "Veamos lo anterior en acción."
      ],
      "metadata": {
        "id": "v0Y34jH8w1mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "standard_scaler = StandardScaler()\n",
        "robust_scaler = RobustScaler()\n",
        "one_hot_encoder = OneHotEncoder(drop='first')"
      ],
      "metadata": {
        "id": "BUmHTMWUw1VW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Opción A: StandardScaler\n",
        "preprocessor_std = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', standard_scaler, numeric_features),\n",
        "        ('cat', one_hot_encoder, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Opción B: RobustScaler\n",
        "preprocessor_robust = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', robust_scaler, numeric_features),\n",
        "        ('cat', one_hot_encoder, categorical_features)\n",
        "    ])"
      ],
      "metadata": {
        "id": "vIgSiD_rx_eg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora apliquemos las transformaciones a nuestro dataset de juguete."
      ],
      "metadata": {
        "id": "-1LLEQKayKIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_std = preprocessor_std.fit_transform(data)\n",
        "X_robust = preprocessor_robust.fit_transform(data)"
      ],
      "metadata": {
        "id": "sMkEdGeOyI1r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, visualicemos las primeras filas a los datos ya preprocesados."
      ],
      "metadata": {
        "id": "DnoIPCzdyRax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n✅ Escalado con StandardScaler + OneHotEncoder:\")\n",
        "print(pd.DataFrame(X_std.toarray() if hasattr(X_std, 'toarray') else X_std))\n",
        "\n",
        "print(\"\\n✅ Escalado con RobustScaler + OneHotEncoder:\")\n",
        "print(pd.DataFrame(X_robust.toarray() if hasattr(X_robust, 'toarray') else X_robust))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bulVcfaNyQTk",
        "outputId": "81866075-0823-4771-dd5d-28401a6ea923"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Escalado con StandardScaler + OneHotEncoder:\n",
            "          0         1    2    3\n",
            "0 -1.382872 -1.116137  0.0  0.0\n",
            "1 -0.856780 -0.850390  0.0  1.0\n",
            "2  0.270562 -0.318896  0.0  0.0\n",
            "3  0.571186  0.744092  1.0  0.0\n",
            "4  1.397904  1.541333  1.0  0.0\n",
            "\n",
            "✅ Escalado con RobustScaler + OneHotEncoder:\n",
            "          0         1    2    3\n",
            "0 -1.157895 -0.500000  0.0  0.0\n",
            "1 -0.789474 -0.333333  0.0  1.0\n",
            "2  0.000000  0.000000  0.0  0.0\n",
            "3  0.210526  0.666667  1.0  0.0\n",
            "4  0.789474  1.166667  1.0  0.0\n"
          ]
        }
      ]
    }
  ]
}